{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77cf6262-8439-47aa-a462-6facddff2b40",
   "metadata": {},
   "source": [
    "# Pytorch基础知识\n",
    "\n",
    "## 安装教程\n",
    "\n",
    "* [官网](https://pytorch.org/get-started/previous-versions/)\n",
    "* [torchaudio](): speech/audio processing\n",
    "* [torchtext](): natural language processing\n",
    "* [torchvision](): computer vision\n",
    "* [skorch](): scikit-learn + PyTorch\n",
    "\n",
    "## 一些有用的GitHub链接\n",
    "* [Huggingface Transformers](https://github.com/huggingface/transformers): transformer models: BERT, GPT, ...\n",
    "* [Fairseq](https://github.com/pytorch/fairseq): sequence modeling for NLP&Speech\n",
    "* [ESPnet](https://github.com/espnet/espnet): speech recognition, translation, synthesis, ...\n",
    "\n",
    "### 验证是否安装成功\n",
    "\n",
    "```python\n",
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)\n",
    "\n",
    "# 验证GPU是否可以使用\n",
    "import torch\n",
    "torch.cuda.is_available()\n",
    "```\n",
    "\n",
    "## 助教教程\n",
    "\n",
    "* [p1](https://speech.ee.ntu.edu.tw/~hylee/ml/ml2021-course-data/hw/Pytorch/Pytorch_Tutorial_1.pdf)\n",
    "* [p2](https://speech.ee.ntu.edu.tw/~hylee/ml/ml2021-course-data/hw/Pytorch/Pytorch_Tutorial_2.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c9d8fd-36f1-4fbb-8828-a307ad2b9b63",
   "metadata": {},
   "source": [
    "## 知识点\n",
    "\n",
    "### PyTorch and TensorFlow\n",
    "\n",
    "1. PyTorch\n",
    "    * 开发商: facebook ai\n",
    "    * 内核: python & c++\n",
    "    * 调试: 简单\n",
    "    * 应用: 研究\n",
    "2. TensorFlow\n",
    "    * 开发商: google brain\n",
    "    * 内核: python, c++, javascript, swift\n",
    "    * 调试: 困难(2.0版本以上简单)\n",
    "    * 应用: 工业\n",
    "\n",
    "### Data Type\n",
    "\n",
    "|data type|dtype|tensor|\n",
    "| :---- | :---- | :---- |\n",
    "|32-bit floating point|torch.float|torch.FloatTensor|\n",
    "|64-bit interger(signed)|torch.long|torch.LongTensor|\n",
    "\n",
    "### 构造tensor\n",
    "\n",
    "1. from list or numpy array\n",
    "2. zeros tensor\n",
    "3. unit tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d9f6d62-fe8f-45ec-b577-2c06d6c7362a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list: \n",
      " [[1, -1], [-1, 1]]\n",
      "from list: \n",
      " tensor([[ 1, -1],\n",
      "        [-1,  1]])\n",
      "from numpy array: \n",
      " tensor([[ 1, -1],\n",
      "        [-1,  1]])\n"
     ]
    }
   ],
   "source": [
    "# from list or numpy array\n",
    "import torch\n",
    "import numpy as np\n",
    "l1 = [[1, -1], [-1, 1]]\n",
    "x = torch.tensor(l1)\n",
    "y = torch.from_numpy(np.array(l1))\n",
    "print('list: \\n', l1)\n",
    "print('from list: \\n', x)\n",
    "print('from numpy array: \\n', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65834f3b-b1f2-49cf-8743-480531df49e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero tensor: \n",
      " tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "unit tensor: \n",
      " tensor([[[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "# zero tensor and unit tensor\n",
    "x = torch.zeros((2,2))\n",
    "y = torch.ones((1,2,5))\n",
    "print('zero tensor: \\n', x)\n",
    "print('unit tensor: \\n', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26eb4d07-b52d-431a-aef4-3e2876210d3f",
   "metadata": {},
   "source": [
    "### 操作tensor\n",
    "\n",
    "1. squeeze: 删除长度为1的指定dimension\n",
    "2. unsqueeze: 扩展新维度\n",
    "3. transpose: 转置两个指定维度\n",
    "4. cat: 拼接多个tensor\n",
    "5. addition\\subtraction\\power\\summation\\mean\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2a1db54-8ff6-4043-ae76-46c76cc47e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# squeeze\n",
    "x = torch.zeros((1,2,3))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b4e70f0-3d64-4849-87ca-939e15b513f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.squeeze(0)  # remove dim=0的维度，因为dim=0的长度是1\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f22946c2-138c-45f5-9cd4-7f77aef33cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unsqueeze\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71c5495e-29c9-4e63-aa84-60c484bfc875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.unsqueeze(1)  # 在dim=1维度长插入长度为1的新增维度，也可以在dim=0\\dim=2\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0cb4530-ce08-40a4-988f-cccf9b3bc402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transpose\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1638568-beda-4c64-8b60-07ce65e69149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.transpose(0, 1)  # dim=0和dim=1交换\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67ebf0a8-60ec-45f9-abd5-279afb5904df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cat\n",
    "x = torch.zeros((2,1,3))\n",
    "y = torch.zeros((2,3,3))\n",
    "z = torch.zeros((2,2,3))\n",
    "w = torch.cat([x,y,z], dim=1)\n",
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c68d3184-db78-4a22-a3f9-d393912aa965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add\\sub\\power\\sum\\mean\n",
    "z = x + y\n",
    "z = x - y\n",
    "y = x.pow(2)\n",
    "y = x.sum()\n",
    "y = x.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf598d5-886f-4367-8289-7a70f96abda1",
   "metadata": {},
   "source": [
    "### pytorch-tensor vs numpy\n",
    "\n",
    "|pytorch|numpy|\n",
    "| :---- | :---- |\n",
    "|x.shape|x.shape|\n",
    "|x.dtype|x.dtype|\n",
    "|x.reshape/x.view|x.reshape|\n",
    "|x.squeeze()|x.sequeeze()|\n",
    "|x.unsqueeze(1)|np.expand_dims(x, 1)|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3049af0-6cbc-4234-bad2-72ce70a2457b",
   "metadata": {},
   "source": [
    "### Device cpu and gpu\n",
    "\n",
    "* default: tensors & modules 默认会使用CPU\n",
    "* 使用cpu: x = x.to('cpu')\n",
    "* 使用GPU: x = x.to('cuda')\n",
    "* 检查是否有nvidia gpu: torch.cuda.is_available()\n",
    "* 多个GPU时：指定'cuda:0', 'cuda:1'...\n",
    "* 为什么使用gpu：并行计算等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d51aa3de-ef94-4e20-a859-ccc3128c3807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93453470-090a-4f05-8c87-e4f289d36034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.to('cpu')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9cce18d-8da6-4a8f-a116-bb90c63675ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.]]], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.to('cuda')\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815103de-e8cb-42eb-a5dc-29126f164d5d",
   "metadata": {},
   "source": [
    "### 如何计算梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b054614-d576-4576-8cba-a7b386ff6366",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17310/3464466715.py:5: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  x.grad  # 得到梯度\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1., 0.], [-1., 1.]], requires_grad=True)  # x=[[1., 0.], [-1., 1.]]\n",
    "x = x.to('cuda')  # 放gpu计算\n",
    "z = x.pow(2).sum()  # z=\\sum_i^j{x_{ij}^2}\n",
    "z.backward()  # 求解梯度：\\alpha z/ \\alpha x_{ij} = 2x_{ij}\n",
    "x.grad  # 得到梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db4fe88e-8b01-466f-9c29-4235d2b2c534",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17310/823061987.py:4: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  x.grad  # 得到梯度\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1., 0.], [-1., 1.]], requires_grad=True).to('cuda')  # x=[[1., 0.], [-1., 1.]]\n",
    "z = x.pow(2).sum()  # z=\\sum_i^j{x_{ij}^2}\n",
    "z.backward()  # 求解梯度：\\alpha z/ \\alpha x_{ij} = 2x_{ij}\n",
    "x.grad  # 得到梯度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467ab297-0274-41c6-b471-b0db43285215",
   "metadata": {},
   "source": [
    "* 上述问题应该是，创建在cpu上的x，再转到cuda上，导致x不是同一个x，则x.grad则是None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bf438c3-5b45-44bb-9e52-f209718c2346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.,  0.],\n",
       "        [-2.,  2.]], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1., 0.], [-1., 1.]], requires_grad=True, device='cuda')  # x=[[1., 0.], [-1., 1.]]\n",
    "z = x.pow(2).sum()  # z=\\sum_i^j{x_{ij}^2}\n",
    "z.backward()  # 求解梯度：\\alpha z/ \\alpha x_{ij} = 2x_{ij}\n",
    "x.grad  # 得到梯度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e380f438-7498-46b9-86ca-8d39a861e63a",
   "metadata": {},
   "source": [
    "### DNN Training Procedure\n",
    "\n",
    "![dnn_procedure.jpg](img/dnn_procedure.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5444d2-75b6-40cb-b553-ff6cb4e0bfcf",
   "metadata": {},
   "source": [
    "### Dataset & DataLoader\n",
    "\n",
    "```python\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, file):\n",
    "        \"\"\"\n",
    "        read data & preprocess\n",
    "        \"\"\"\n",
    "        self.data = file\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        returns one sample at a time\n",
    "        \"\"\"\n",
    "        return self.data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        returns the size of the dataset\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "```\n",
    "\n",
    "![dataset_dataloader.jpg](img/dataset_dataloader.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6297b293-8500-4417-89b2-46cac0ca3e82",
   "metadata": {},
   "source": [
    "### Layers\n",
    "\n",
    "![layers.jpg](img/layers.jpg)\n",
    "\n",
    "![layers1.jpg](img/layers1.jpg)\n",
    "\n",
    "![layers2.jpg](img/layers2.jpg)\n",
    "\n",
    "```python\n",
    "layer = torch.nn.Linear(32, 64)\n",
    "layer.weight.shape\n",
    "layer.bias.shape\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5557618-f04b-4113-aebe-2d4441fb5cab",
   "metadata": {},
   "source": [
    "### 激活函数\n",
    "\n",
    "![activation_func.jpg](img/activation_func.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b56279-5b40-4346-98d6-fb69e40f0b4f",
   "metadata": {},
   "source": [
    "### 损失函数\n",
    "\n",
    "![loss_func.jpg](img/loss_func.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1311a2cc-3792-4b08-b485-7c89c7eeb492",
   "metadata": {},
   "source": [
    "### 自定义网络结构\n",
    "\n",
    "```python\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(10, 32),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd211c0-c86e-4f45-a6d0-b07f02c9ffcb",
   "metadata": {},
   "source": [
    "### 优化函数\n",
    "\n",
    "![optim_func.jpg](img/optim_func.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44ecc27-af29-4687-9e3f-644458b3cd8f",
   "metadata": {},
   "source": [
    "### 模型训练\n",
    "\n",
    "```python\n",
    "dataset = MyDataset(file)  # read data via MyDataset\n",
    "tr_set = DataLoader(dataset, 16, shuffle=True)  # put dataset into DataLoader\n",
    "model = MyModel().to(device)  # contruct model and move to device(cpu/cuda)\n",
    "criterion = nn.MSELoss()  # set loss function\n",
    "optimizer = torch.optim.SGD(model.parameters(), 0.1)  # set optimizer\n",
    "\n",
    "for epoch in range(n_epochs):  # iterate n_epochs\n",
    "    model.train()  # set model to train mode\n",
    "    for x, y in tr_set:  # iterate through the dataloader\n",
    "        optimizer.zero_grad()  # set gradient to zero\n",
    "        x, y = x.to(device), y.to(device)  # move data to device(cpu/cuda)\n",
    "        pred = model(x)  # forward pass(compute output)\n",
    "        loss = criterion(pred, y)  # compute loss\n",
    "        loss.backward()  # compute gradient(backpropagation反向传播)\n",
    "        optimizer.step()  # update model with optimizer\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b1af95-41a6-450c-9ae1-832534d2a1f1",
   "metadata": {},
   "source": [
    "### 验证集计算\n",
    "\n",
    "```python\n",
    "model.eval()  # set model to evaluation mode\n",
    "total_loss = 0\n",
    "for x, y in dv_set:  # iterate through the dataloader\n",
    "    x, y = x.to(device), y.to(device)  # move data to device(cpu/cuda)\n",
    "    with torch.no_grad():  # disable gradient calculation\n",
    "        pred = model(x)  # forward pass(compute output)\n",
    "        loss = criterion(pred, y)  # compute loss\n",
    "    total_loss += loss.cpu().item()*len(x)  # accumulate loss\n",
    "    avg_loss = total_loss / len(dv_set.dataset)  # compute averaged loss\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900243c4-7105-4ecc-b079-8b095e79227c",
   "metadata": {},
   "source": [
    "### 测试集计算\n",
    "\n",
    "```python\n",
    "model.eval()  # set model to evaluation mode\n",
    "preds = []\n",
    "for x in tt_set:  # iterate through the dataloader\n",
    "    x = x.to(device)  # move data to device(cpu/cuda)\n",
    "    with torch.no_grad():  # disable gradient calculation\n",
    "        pred = model(x)  # forward pass(compute output)\n",
    "        preds.append(pred.cpu())  # collect prediction\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584abd09-8e08-4622-9a97-4365a55da045",
   "metadata": {},
   "source": [
    "### 保存/恢复模型\n",
    "\n",
    "```python\n",
    "# save\n",
    "torch.save(model.state_dict(), path)\n",
    "\n",
    "# load\n",
    "ckpt = torch.load(path)\n",
    "model.load_state_dict(ckpt)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b298f4b-d6d1-49a9-92e5-dd50934fec71",
   "metadata": {},
   "source": [
    "### 一些常见错误"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7a3c1e4-fe33-4d0d-825a-1e906c95d0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  Tensor on Different Device to Model\n",
    "# model = torch.nn.Linear(5, 1).to('cuda')\n",
    "# x = torch.Tensor([1,2,3,4,5]).to('cpu')\n",
    "# y = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00a98fb6-260b-44b7-9c34-23c623b446e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# send the tensor to GPU\n",
    "model = torch.nn.Linear(5, 1).to('cuda')\n",
    "x = torch.Tensor([1,2,3,4,5]).to('cuda')\n",
    "y = model(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b59b4f2e-1214-4e68-8fd4-8db5f2d89da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Mismatched Dimensions\n",
    "# x = torch.randn(4, 5)\n",
    "# y = torch.randn(5, 4)\n",
    "# z = x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c206513d-fe73-4fe3-834d-ab2e25d1db61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the shape of a tensor is incorrect, use transpose, squeeze, unsqueezeto align the dimensions\n",
    "x = torch.randn(4, 5)\n",
    "y = torch.randn(5, 4)\n",
    "y = y.transpose(0, 1)\n",
    "z = x + y\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc0e5adc-fab5-4684-9359-d2d61b7c7aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cuda out of memory\n",
    "# import torch\n",
    "# import torchvision.models as models\n",
    "# resnet18 = models.resnet18().to('cuda')\n",
    "# data = torch.randn(512, 3, 244, 244)\n",
    "# out = resnet18(data.to('cuda'))\n",
    "# out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27d1fd92-b6d2-4610-b4b1-0071de2ca2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The batch size of data is too large to fit in the GPU. Reduce the batch size\n",
    "# import torch\n",
    "# import torchvision.models as models\n",
    "# resnet18 = models.resnet18().to('cuda')\n",
    "# data = torch.randn(512, 3, 244, 244)\n",
    "# data.shape\n",
    "# for d in data:\n",
    "#     out = resnet18(data.to('cuda').unsqueeze(0))\n",
    "# out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a03ed0d3-a19f-44a9-8508-bb9616c46b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  Mismatched Tensor Type\n",
    "# import torch.nn as nn\n",
    "# L = nn.CrossEntropyLoss()\n",
    "# outs = torch.randn(5, 5)\n",
    "# labels = torch.Tensor([1,2,3,4,0])\n",
    "# lossval = L(outs, labels)\n",
    "# lossval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a4bfd9a-bc58-4016-a4c4-c805986e12a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9904)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "L = nn.CrossEntropyLoss()\n",
    "outs = torch.randn(5, 5)\n",
    "labels = torch.Tensor([1,2,3,4,0])\n",
    "labels = labels.long()\n",
    "lossval = L(outs, labels)\n",
    "lossval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff8e632-34cf-4a7e-ad87-66168d46a1e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "env_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
